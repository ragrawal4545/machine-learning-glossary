{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Introduction for VIP Students\n",
    "#### Fall 2018, Jana Boerger, Georgia Institute of Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "**Goal:** Overview over ressources and tools to enable you to self study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is Machine Learning?\n",
    "    * Supervised vs Unsupervised Learning\n",
    "    * The three steps in ML\n",
    "2. Tools\n",
    "3. First Examples\n",
    "4. What is Multiclass Classification?\n",
    "5. Evaluation/Validation\n",
    "\n",
    "Things to remember\n",
    "\n",
    "\n",
    "References & Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "\n",
    "## 1. What is Machine Learning?\n",
    "\n",
    "* The use or study of algorithms to fulfill a learning task\n",
    "* Learning: “Learning is any process by which a system improves  performance from experience.”- Herbert Simon \n",
    "* ML models can learn by example and then generalise to new data\n",
    "\n",
    "### Supervised Learning vs Unsupervised Learning\n",
    "**Supervised**: labelled training data [Task: Inference]: Examples: Regression, Classification\n",
    "\n",
    "**Unsupervised**: unlabelled training data [Task: Model]: Examples: Clustering\n",
    "\n",
    "\n",
    "### Representation \n",
    "- how do I want to represent data? (e.g. pixel matrix to represent photo)\n",
    "- what ML algorithm would I like to use? (**[Cheat sheet](http://scikit-learn.org/dev/tutorial/machine_learning_map/index.html)**)\n",
    "\n",
    "### Evaluation\n",
    "- e.g.: how accurate is my classifier?\n",
    "\n",
    "### Optimization\n",
    "- what parameters will give me the best result?\n",
    "\n",
    "\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tools\n",
    "\n",
    "### NumPy\n",
    "provides  important data structures that are used by pandas, scikit-learn etc.: e.g. multi-dimensional arrays\n",
    "### SciPy\n",
    "scientific computing tools: statistical distributions, linear algebra etc.\n",
    "### pandas\n",
    "helps data analysis and data manipulation through structures such as DataFrame (might sound familiar if you've used R before)\n",
    "### matplotlib\n",
    "plotting library (matplotlib.pyplot: MATLAB like plotting)\n",
    "\n",
    "(seaborn)\n",
    "### scikit-Learn\n",
    "Python Machine Learning Library - [scikit-learn userguide](http://scikit-learn.org/stable/user_guide.html) - [class and function reference](http://scikit-learn.org/stable/modules/classes.html) - [cheat sheet](http://scikit-learn.org/dev/tutorial/machine_learning_map/index.html)\n",
    "\n",
    "### Deep Learning Libraries\n",
    "tensorflow, keras\n",
    "\n",
    "### Google and Stackoverflow\n",
    "Google and Stackoverflow are your friends!\n",
    "\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries that we'll use\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Regression\n",
    "Given data points: $(x_1, y_1), (x_2, y_2),... ,(x_n, y_n)$ we want to predict the y for a new x. So we want to learn a function $f(x)$ to predict y given x. Here, y is a real number.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Linear Regression is a simple but nevertheless very powerful tool. It is linear in the model but the entries of could be complicated functions? If you have the right non-linear features, a linear fit can still perform very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "boston = datasets.load_boston()\n",
    "price = boston.target\n",
    "print (boston.DESCR)\n",
    "\n",
    "# you do not need to go to the link - the data loads through the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas dataframe, assign column names and check the shape of our dataframe\n",
    "df = pd.DataFrame(boston.data)\n",
    "df.columns = boston.feature_names\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input into our algorithm is a table. One row corresponds to one example and one column corresponds to one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first rows of dataframe\n",
    "df.head()\n",
    "#RM = average number of rooms per dwelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTBEYhmHUOaYIDMMw6hxTBIZhGHXO/wUxS0LLCYZ2rQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d88f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create scatterplot of price over the average rooms\n",
    "plt.scatter(df['RM'], price, s=10)\n",
    "plt.xlabel('Average Number of Rooms')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Average Number of Rooms and Prices')\n",
    "# plt.plot(x, y, color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reshape arrays\n",
    "rooms = df['RM'].values\n",
    "rooms = rooms.reshape(-1,1)\n",
    "price = price.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit linear function\n",
    "lm.fit(rooms, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-34.670620776438568"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show intercept\n",
    "lm.intercept_\n",
    "intercept = lm.intercept_[0]\n",
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.1021089811803098"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show coefficient(s)\n",
    "lm.coef_\n",
    "coef = lm.coef_[0, 0]\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.83992413]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How expensive is an area with an average of 5 dwellings?\n",
    "lm.predict(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make array with entries 3 to 10\n",
    "x = np.arange(3, 11)\n",
    "\n",
    "# create y values with the values we got\n",
    "y = intercept + coef * x\n",
    "\n",
    "# now, you can go back to the plotting cell and uncomment the plt.plot line which will draw the regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted = lm.predict(rooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48352545599133423"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(price, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406077428649428"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(df, price)\n",
    "new_predicted = lm.predict(df)\n",
    "r2_score(price, new_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "#### How do we know if our regression model is any good?  $R^2$\n",
    "\n",
    "Goodness-of-fit - how well does my model fit the data?\n",
    "\n",
    "value between 0 and 1\n",
    "\n",
    "do not rely on $R^2$ alone! check out residual plots\n",
    "\n",
    "*******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More things to look at in Regression:\n",
    "\n",
    "* **Ridge Regression**\n",
    "\n",
    "(from sklearn.linear_model import Ridge)\n",
    "* **Lasso Regression**\n",
    "\n",
    "\n",
    "* **Feature Normalisation** (what is it? when/why is it necessary? e.g. MinMaxScaler in sklearn.preprocessing)\n",
    "* **Polynomial Features** in Linear Regression\n",
    "\n",
    "(from sklearn.preprocessing import PolynomialFeatures)\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "Given data points: $(x_1, y_1), (x_2, y_2),... ,(x_n, y_n)$ we want to predict the y for a new x. So we want to learn a function $f(x)$ to predict y given x. Here, y is categorical.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Write Classifier to classify the three different types of flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['data']"
   ]
  },
  
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "\n",
    "## 4. What is Multiclass Classification?\n",
    "\n",
    "Multiclass (or multinomial) classification refers to the classification of instances into one class from a set of more than two classes. It involves the construction of a function, which, given a new data point, will correctly predict the class to which the point belongs. Note that this is separate from multi-label classification, which involves applying multiple labels/classes to each instance.\n",
    "The general approach to multiclass classification is to decompose it into a series of binary classification problems involving multiple binary classifiers. This transformation to binary classification is popularly conducted via One Vs. All (OVA) or All Vs. All (or One Vs. One, or AVA) approaches. The choice between the approaches is largely computational. \n",
    "\n",
    "### One Vs. All\n",
    "Consider a multi=class classification problem involving N classes (i = 1,2.....N). To perform OVA, one trains N - many binary classifiers, f1,.....fN. Each classifier is trained on the entire training data set. Now, the ith classifier, fi receives all examples labelled class i as positive examples, and all points not in class i as negative examples. At test time, whichever classifier predicts "positive" dominates the function, with ties broken randomly. Thus, the classification function yields\n",
    "\n",
    "*f(x) = arg max fi(x)\n"
    "This performance approach works well with well chosen, larger binary classifier algorithms with tuned hyperparameters. However, as is evident, it is brittle - one erroneous classifier can render the entire classification inaccurate. It can solve one RLS problem over an entire data set using matrix factorization more efficiently than AVA.\n",
    "\n",
    "\n",
    "### OVA Error Bound \n",
    "If the average binary error of N binary classifiers is ε, then the error rate of OVA predication is at most (k - 1)ε. In other words, it scales linearly in k. As the number of classifiers increases, so does the expected error in precision.\n",
    "\n",
    
     "### All Vs. All\n",
    "Consider a multiclass classification problem involving N classes. (N 2) = N(N - 1) binary classifiers are trained. Consider the classifier, fij, which is trained to distinguish between the pair of classes i and j. All class i examples are labelled positive, and those in class j are labelled negative, and fed to the classifiers. When the test point arrives, it runs through all classifiers. If the classifier fij predicts positive, class i gets a point, otherwise, class j gets a point. After funning through all classifiers, the class with most points is the determined class, as shown by the following function.\n",
    "\n",
    "*f(x) = arg max ( sigma fij(x) ))\n"
    "This performance approach works well with well chosen, larger binary classifier algorithms with tuned hyperparameters. However, as is evident, it is brittle - one erroneous classifier can render the entire classification inaccurate. It can solve one RLS problem over an entire data set using matrix factorization more efficiently than AVA.\n",
    "\n",
    "\n",
    "### AVA Error Bound \n",
    "If the average binary error of N(N - 1) binary classifiers is ε, then the error rate of AVA predication, with a binary tree of classifiers, is at most (log2(k))ε. AVA is faster and more memory efficient, especially with smaller classifiers, so if time to build the classifiers is linear with the number of data points, it is considered.\n",
    "\n",

    "*****"
   ]
  },
  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "\n",
    "## 5. Evaluation/Validation\n",
    "\n",
    "### Accuracy\n",
    "If the data set is balanced, that is, when there is a roughly similar number of data points for each class to classify, accuracy is a good metric to place the classifier results in context. If dataset is imbalanced, it can be misleading.\n"\n",
    "\n",
    "*True Positive / (Entire data set)\n"
    "Useful when the model should avoid either false positives or false negatives or when the data set is unbalanced.\n",
    "\n",
    "\n",
    "### Precision \n",
    "Given a class prediction from the classifier, how likely is it to be correct? Precision is cautious about False Positives.\n",
    "*True Positive / (True Positive + False Positive)\n"
    "\n",
    "### Recall \n",
    "Given a class, will the classifier detect it? Recall is cautious about false negatives.\n",
    "*True Positive / (True Positive + False Negative)\n"
    "\n",
    "### F score / F1 Score / Fβ Score \n",
    "F score attempts to combine precision and recall to create a unified metric:\n",
    "*Fβ score: (1 + β^2) (precision x recall) / (( β^2 x precision) + recall)\n",
    "Higher β means precision will be weighted more than recall. It is the harmonic mean of recall and precision, punishing extreme values more. This is why it is useful for imbalanced data. F1 score is when β = 1 (balanced).\n",
    "\n",
    

    "*****"
   ]
  },
  
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "### Things to remember\n",
    "* Pre processing of data and exploratory data analysis is important. (Missing values? consistent use of features?)\n",
    "* Don't overcomplicate and overtheorize. Start with something small that you can easily oversee and build up from there\n",
    "* Bias vs. Variance trade-off   **([Quora Discussion](https://www.quora.com/What-is-the-best-way-to-explain-the-bias-variance-trade-off-in-layman’s-terms))**\n",
    "* Overfitting (split your data into a training and a test set: e.g. train_test_split from sklearn.model_selection)\n",
    "* Validation and Verification (Am I using the correct model? Am I using the model correctly?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "### Questions to think about (we might ask you about these on Friday!)\n",
    "* What is a feature in a ML model?\n",
    "* Name three ML algorithms\n",
    "* What is cross validation and why do we need it?\n",
    "* When doing classification: what is recall and what is precision? - what is the trade-off? When to use one; when to use the other?\n",
    "* What is data leakage and how can we prevent it?\n",
    "* What does it mean for a model to overfit? Is a classifier that has less training data less likely to overfit?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "### References & Ressources\n",
    "\n",
    "**Books:**\n",
    "* [Introduction to Statistical Learning - Hastie et al.](http://www-bcf.usc.edu/~gareth/ISL/) (good first introduction to ML | free (and legal) to download)\n",
    "* [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do) (applied: numpy, pandas, ipython)\n",
    "* [Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do) (applied: scikit-learn)\n",
    "* [Elements of Statistical Learning - Hastie et al.](https://web.stanford.edu/~hastie/ElemStatLearn/) (advanced)\n",
    "* [Pattern Recognition and Machine Learning - Bishop](http://www.springer.com/de/book/9780387310732) (advanced)\n",
    "\n",
    "**Datasets:**\n",
    "* [kaggle](www.kaggle.com) (Data Science Competitions & data sets)\n",
    "* [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)\n",
    "\n",
    "**Python:**\n",
    "* [Googles Introduction Python Course](https://developers.google.com/edu/python/)\n",
    "* Pandas: [10 Minutes to Pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "\n",
    "**Lecture Notes:**\n",
    "* [ISYE 4641: Machine Learning (by Byron Boots)](https://www.cc.gatech.edu/~bboots3/CS4641-Fall2016/)\n",
    "* [Stanford Machine Learning Introduction Course (by Andrew Ng)](http://cs229.stanford.edu/syllabus.html)\n",
    "\n",
    "**MOOC:**\n",
    "* [Coursera: University of Michigan: Applied Machine Learning in Python](https://www.coursera.org/learn/python-machine-learning) (free, if taken without certificate of accomplishment)\n",
    "\n",
    "**Website:**\n",
    "* [Machine Learning Mastery](https://machinelearningmastery.com/start-here/) (Applied ML; Have not read it myself, but a friend told me it's been a very useful resource to him)\n",
    "\n",
    "**Conferences:**\n",
    "\n",
    "You can check out proceedings from the previous years to see what people are working on.\n",
    "* [ICML](https://icml.cc)\n",
    "* [NIPS](https://nips.cc)\n",
    "\n",
    "**Other**\n",
    "* [A few useful things to know about Machine Learning - Domingos](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
